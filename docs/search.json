[
  {
    "objectID": "431-movies-analysis1.html",
    "href": "431-movies-analysis1.html",
    "title": "Your Favorite Movies: Analysis 1",
    "section": "",
    "text": "library(Hmisc)\nlibrary(janitor)\nlibrary(naniar)\n\nlibrary(xfun) ## or, if you prefer use library(sessioninfo)\n\nlibrary(googlesheets4)\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(mosaic)\nlibrary(car) # for Box-Cox\n\nlibrary(broom)\nlibrary(patchwork)\n\nlibrary(tidyverse)\n\ntheme_set(theme_bw())\nknitr::opts_chunk$set(comment = NA)"
  },
  {
    "objectID": "431-movies-analysis1.html#variables",
    "href": "431-movies-analysis1.html#variables",
    "title": "Your Favorite Movies: Analysis 1",
    "section": "6.1 Variables",
    "text": "6.1 Variables\nThe two key variables we are studying in this analysis are quantitative, and we are interested in the association between them.\nOur outcome is imdb_stars, which is a proprietary rating available for each film on IMDB, identified on a scale from 1 (lowest) to 10 (highest).\nOur predictor is imdb_pct10, which is the percentage of user ratings, across the world, which rated the movie as a 10 on the 1-10 scale.\nEach is identified in R a quantitative variable, and neither display any missing values within our sample, so we have a complete set of 201 movies.\n\n\n\n\n\n\nWhat to do about missing data\n\n\n\nIn Project A, I would begin Analysis 1 by either filtering to complete cases or singly imputing any missing values. You should make a statement about what you are assuming about the missing data mechanism (either MCAR or MAR is reasonable - do not assume MNAR in Project A, no matter how compelling an argument might be) if you have missing values.\nIf you don’t have missing values in the variables used in this analysis, there is no reason to specify a missing data mechanism or do any filtering or imputation."
  },
  {
    "objectID": "431-movies-analysis1.html#summaries",
    "href": "431-movies-analysis1.html#summaries",
    "title": "Your Favorite Movies: Analysis 1",
    "section": "6.2 Summaries",
    "text": "6.2 Summaries\n\n6.2.1 Graphical Summaries of the Outcome-Predictor Association\nHere is an initial plot of the data, before considering any transformations.\n\nggplot(movies1, aes(x = imdb_pct10, y = imdb_stars)) +\n  geom_point(col = \"black\") +\n  geom_smooth(method = \"lm\", col = cwru_trueblue, formula = y ~ x, se = TRUE) +\n  geom_smooth(method = \"loess\", col = cwru_darkblue, formula = y ~ x, se = FALSE) +\n  labs(x = \"% of Ratings that are 10 out of 10\", y = \"IMDB Stars\",\n       title = \"Favorite Movies Sample for Fall 2023\",\n       caption = str_glue(\"Pearson correlation = \", \n                          round_half_up(cor(movies1$imdb_pct10, \n                                            movies1$imdb_stars), 3)),\n       subtitle = \"% of 10s and Stars seem to move together\")\n\n\n\n\nThe association between “% of 10s” and “star rating” appears to have a positive slope, and be fairly strong (with a Pearson correlation of 0.679. The loess smooth suggests there is some potential for non-linearity, and some of the films (especially those with relatively low star ratings) are poorly fit by the simple linear regression model shown in red above.\n\n\n\n\n\n\nWhat I would show\n\n\n\nIn Project A, if you choose to use a transformation, I would show only two scatterplots in this section: the one of the raw outcome-predictor relationship, and the one with the transformation you choose to employ, rather than showing all possibilities as I have done here.\nIn Project A, if you choose not to use a transformation, I would again show only two scatterplots: the one of the raw outcome-predictor relationship, and the one transformation that you felt was best among those you considered. Do not show us all of the plots you fit.\n\n\nGiven the curve in the loess smooth, I attempted several transformations of the outcome. The most appealing transformation I found was to take the square of the outcome, shown in the lower right of the four plots below.\n\np1 &lt;- ggplot(movies1, aes(x = imdb_pct10, y = imdb_stars)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_trueblue, formula = y ~ x, se = FALSE) +\n  labs(title = \"imdb_stars vs. imdb_pct10\")\n\np2 &lt;- ggplot(movies1, aes(x = imdb_pct10, y = log(imdb_stars))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_trueblue, formula = y ~ x, se = FALSE) +\n  labs(title = \"log(imdb_stars) vs. imdb_pct10\")\n\np3 &lt;- ggplot(movies1, aes(x = imdb_pct10, y = 1/imdb_stars)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_trueblue, formula = y ~ x, se = FALSE) +\n  labs(title = \"1/imdb_stars vs. imdb_pct10\")\n\np4 &lt;- ggplot(movies1, aes(x = imdb_pct10, y = imdb_stars^2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_trueblue, formula = y ~ x, se = FALSE) +\n  labs(title = \"imdb_stars^2 vs. imdb_pct10\")\n\n(p1 + p2) / (p3 + p4)\n\n\n\n\nI decided that the value of the square transformation of the outcome was pretty minimal in this setting, relative to the increased difficulty it created in interpreting the results, so I opted not to make a transformation.\n\n\n\n\n\n\nShould I use / show the Box-Cox plot?\n\n\n\nBasically, I would suggest that you use the Box-Cox plot to suggest a potential transformation of the outcome if you want to, but please do not feel obligated. If you use the plot to make your transformation decision, though, you should show it.\n\n\nNote that the Box-Cox approach in this setting (as shown below) suggests trying the square of our outcome as a transformation, since the \\(\\lambda\\) value near 2 maximizes the log-likelihood. That doesn’t mean I have to do it.\n\nboxCox(movies1$imdb_stars ~ movies1$imdb_pct10)\n\n\n\n\n\n\n\n\n\n\nShould I consider transforming the predictor as well?\n\n\n\nAnother approach I might have taken was to consider transforming both the outcome and the predictor. Were I to do that in Project A, I think I would restrict myself to using the same transformation on each variable, as shown below, but again, I would not display any of these transformations unless they were the transformation I chose to use, or they were the best transformation of the data (even though I decided not to use it)\n\n\nHere are the plots I developed to consider a transformation of both the outcome and the predictor.\n\np5 &lt;- ggplot(movies1, aes(x = imdb_pct10, y = imdb_stars)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_terracottaorange, \n              formula = y ~ x, se = FALSE) +\n  labs(title = \"imdb_stars vs. imdb_pct10\")\n\np6 &lt;- ggplot(movies1, aes(x = log(imdb_pct10), y = log(imdb_stars))) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_terracottaorange, \n              formula = y ~ x, se = FALSE) +\n  labs(title = \"log(imdb_stars) vs. log(imdb_pct10)\")\n\np7 &lt;- ggplot(movies1, aes(x = 1/imdb_pct10, y = 1/imdb_stars)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_terracottaorange, \n              formula = y ~ x, se = FALSE) +\n  labs(title = \"1/imdb_stars vs. 1/imdb_pct10\")\n\np8 &lt;- ggplot(movies1, aes(x = imdb_pct10^2, y = imdb_stars^2)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", col = cwru_terracottaorange, \n              formula = y ~ x, se = FALSE) +\n  labs(title = \"imdb_stars^2 vs. imdb_pct10^2\")\n\n(p5 + p6) / (p7 + p8)\n\n\n\n\nI see no real benefit from any of these transformations, so I will proceed to model the original outcome (imdb_stars) as a function of the original predictor (imdb_pct10.)\n\n\n6.2.2 Graphical Summaries of the Outcome’s Distribution\nHere are some plots of the sample distribution of the outcome I have selected, which is, of course, the raw imdb_stars variable. I would include any plots you find helpful in assessing whether a Normal distribution is a reasonable approximation for your outcome.\n\n\n\n\n\n\nNote\n\n\n\nHad I decided to use a transformation of the outcome, I would instead present plots of the transformed values.\n\n\n\n## Normal Q-Q plot\np1 &lt;- ggplot(movies1, aes(sample = imdb_stars)) +\n  geom_qq(col = cwru_blue, size = 2) + geom_qq_line(col = cwru_trueblue) +\n  theme(aspect.ratio = 1) + \n  labs(title = \"Normal Q-Q plot\",\n       y = \"IMDB Stars Rating\",\n       x = \"Expectation under Standard Normal\")\n\n## Histogram with Normal density superimposed\np2 &lt;- ggplot(movies1, aes(imdb_stars)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 7, fill = cwru_blue, col = cwru_lightgray) +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(movies1$imdb_stars, na.rm = TRUE), \n                            sd = sd(movies1$imdb_stars, na.rm = TRUE)),\n                col = cwru_darkgray, lwd = 1.5) +\n  labs(title = \"Histogram with Normal Density\",\n       x = \"IMDB Stars Rating\")\n\n## Boxplot with notch and rug\np3 &lt;- ggplot(movies1, aes(x = imdb_stars, y = \"\")) +\n  geom_boxplot(fill = cwru_blue, notch = TRUE, \n               outlier.color = cwru_blue, outlier.size = 2) + \n  stat_summary(fun = \"mean\", geom = \"point\", \n               shape = 23, size = 3, fill = cwru_lightgray) +\n  geom_rug(sides = \"b\") +\n  labs(title = \"Boxplot with Notch and Rug\",\n       x = \"IMDB Stars Rating\",\n       y = \"\")\n\np1 + (p2 / p3 + plot_layout(heights = c(4,1))) +\n  plot_annotation(title = \"IMDB Stars Rating\",\n                  subtitle = str_glue(\"Our Favorite Movies: (n = \", \n                                      nrow(movies1), \")\"),\n      caption = str_glue(\"IMDB Stars: Sample Size = \", nrow(movies1), \n                         \", Sample Median = \", round_half_up(median(movies1$imdb_stars),1),\n                         \", Mean = \", round_half_up(mean(movies1$imdb_stars),2), \n                         \" and SD = \", round_half_up(sd(movies1$imdb_stars),2)))\n\n\n\n\nSeveral movies are identified here as low outliers. Here’s the set of films with the five lowest IMDB stars ratings in our sample.\n\nmovies1 |&gt; arrange(imdb_stars) |&gt; head(5)\n\n# A tibble: 5 × 4\n  film_id film                  imdb_stars imdb_pct10\n  &lt;chr&gt;   &lt;chr&gt;                      &lt;dbl&gt;      &lt;dbl&gt;\n1 61      The Gingerdead Man           3.4        9.3\n2 163     The Room                     3.6       22.6\n3 115     Madea Goes To Jail           4.5       15.4\n4 78      High School Musical 2        5.2       14.4\n5 83      House Party 2                5.3        9.4\n\n\n\n\n6.2.3 Numerical Summaries\n\nkey1 &lt;- \n  bind_rows(\n    favstats(~ imdb_stars, data = movies1),\n    favstats(~ imdb_pct10, data = movies1)) |&gt;\n  mutate(variable = c(\"imdb_stars\", \"imdb_pct10\")) |&gt;\n  relocate(variable)\n\nkey1 |&gt; gt() |&gt; gt_theme_dark()\n\n\n\n\n\n  \n    \n    \n      variable\n      min\n      Q1\n      median\n      Q3\n      max\n      mean\n      sd\n      n\n      missing\n    \n  \n  \n    imdb_stars\n3.4\n7.1\n7.8\n8.1\n9.3\n7.562687\n0.8798015\n201\n0\n    imdb_pct10\n3.8\n11.6\n15.6\n22.2\n55.0\n17.525373\n9.0971646\n201\n0\n  \n  \n  \n\n\n\n\nAgain, I’ll note that I have no missing values to deal with in this sample.\n\n\n\n\n\n\nNote\n\n\n\nHad I decided to use a transformation here, I would have summarized these transformed values, as well."
  },
  {
    "objectID": "431-movies-analysis1.html#approach",
    "href": "431-movies-analysis1.html#approach",
    "title": "Your Favorite Movies: Analysis 1",
    "section": "6.3 Approach",
    "text": "6.3 Approach\n\n6.3.1 Fitted Model\nHere is the main model I chose to fit, which is a linear regression predicting imdb_stars using imdb_pct10 across our sample of movies.\n\nm1 &lt;- lm(imdb_stars ~ imdb_pct10, data = movies1)\n\ntidy(m1, conf.int = TRUE, conf.level = 0.90) |&gt; \n  gt() |&gt; fmt_number(columns = where(is.numeric), decimals = 3) |&gt;\n  gt_theme_guardian()\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n6.411\n0.099\n64.578\n0.000\n6.247\n6.575\n    imdb_pct10\n0.066\n0.005\n13.062\n0.000\n0.057\n0.074\n  \n  \n  \n\n\n\nglance(m1) |&gt; select(r.squared, sigma, nobs) |&gt; \n  gt() |&gt; fmt_number(columns = where(is.numeric), decimals = 3) |&gt;\n  gt_theme_guardian()\n\n\n\n\n\n  \n    \n    \n      r.squared\n      sigma\n      nobs\n    \n  \n  \n    0.462\n0.647\n201.000\n  \n  \n  \n\n\n\n\nThe fitted model equation is imdb_stars = 6.411 + 0.066 imdb_pct10. We fit the model to all 201 observations, obtaining a model \\(R^2\\) value of 46.2% and a residual standard deviation of 0.647, as compared to the initial standard deviation of the imdb_stars values, which was 0.880, from our earlier numerical summaries.\n\n\n6.3.2 Residual Analysis\n\npar(mfrow=c(1,2)); plot(m1, which = 1:2); par(mfrow = c(1,1))\n\n\n\n\nThe residual plots are pretty disappointing. We have clear evidence of non-Normality in the Q-Q plot of the residuals, and some suggestion of a downward curve as the fitted values increase. So we are likely to have substantial problems with the assumptions of both linearity and Normality if we decide to use this model.\nThe three outlying movies identified in this analysis are the three films with the largest negative residuals from the model, and are listed below.\n\nmovies1_aug &lt;- augment(m1, data = movies1)\nmovies1_aug |&gt; slice(163, 61, 115) |&gt; \n  select(film_id, film, imdb_stars, imdb_pct10, .fitted, .resid, .std.resid) |&gt;\n  gt() |&gt; gt_theme_guardian()\n\n\n\n\n\n  \n    \n    \n      film_id\n      film\n      imdb_stars\n      imdb_pct10\n      .fitted\n      .resid\n      .std.resid\n    \n  \n  \n    163\nThe Room\n3.6\n22.6\n7.896122\n-4.296122\n-6.659935\n    61\nThe Gingerdead Man\n3.4\n9.3\n7.022227\n-3.622227\n-5.622419\n    115\nMadea Goes To Jail\n4.5\n15.4\n7.423036\n-2.923036\n-4.528427\n  \n  \n  \n\n\n\n\nThese are also the three movies with the smallest number of imdb_stars in the initial data."
  },
  {
    "objectID": "431-movies-analysis1.html#conclusions",
    "href": "431-movies-analysis1.html#conclusions",
    "title": "Your Favorite Movies: Analysis 1",
    "section": "6.4 Conclusions",
    "text": "6.4 Conclusions\n\n\n\n\n\n\nNote\n\n\n\nHere, I’m just repeating the relevant instructions from the Project A Analysis page.\nDoing this work is, of course, a big part of your job.\n\n\nFor Analysis 1, you’ll write two paragraphs.\nIn the first paragraph, you should provide a clear restatement of your research question, followed by a clear and appropriate response to your research question, motivated by your results. Most of the time, one model won’t let you come to a strong conclusion about a question of interest, and it is your job to accurately present what information can be specified as a result of the model, without overstating your conclusions.\nThen, write a paragraph which summarizes the key limitations of your work in Analysis 1.\n\nIf you see problems with regression assumptions in your residual plot, that would be a good thing to talk about here, for instance.\nAnother issue that is worth discussing is your target population, and what evidence you can describe that might indicate whether your selected states are a representative sample of the US as a whole, or perhaps some particular part of the United States.\nYou should also provide at least one useful “next step” that you could take to improve this analysis (just saying “get more data” isn’t a sufficient next step.)"
  },
  {
    "objectID": "431-movies-analysis2.html",
    "href": "431-movies-analysis2.html",
    "title": "Your Favorite Movies: Analysis 2",
    "section": "",
    "text": "library(Hmisc)\nlibrary(janitor)\nlibrary(naniar)\n\nlibrary(xfun) ## or, if you prefer use library(sessioninfo)\n\nlibrary(googlesheets4)\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(mosaic)\n\nlibrary(broom)\nlibrary(patchwork)\n\nlibrary(tidyverse)\n\nurl_boost &lt;- \"https://raw.githubusercontent.com/THOMASELOVE/431-data/main/data-and-code/Love-boost.R\"\n\nsource(url_boost) ## to get Love-boost.R functions like bootdif()\n\ntheme_set(theme_bw())\nknitr::opts_chunk$set(comment = NA)"
  },
  {
    "objectID": "431-movies-analysis2.html#variables",
    "href": "431-movies-analysis2.html#variables",
    "title": "Your Favorite Movies: Analysis 2",
    "section": "6.1 Variables",
    "text": "6.1 Variables\nHere our key variables include a quantitative outcome and a two-level predictor. We are interested in understanding something about the difference in imdb_stars between movies Dr. Love has and has not seen.\nOur outcome is imdb_stars, which is a proprietary rating available for each film on IMDB, identified on a scale from 1 (lowest) to 10 (highest).\nOur predictor is dr_love, which is an indicator of whether Dr. Love has seen the movie. The available levels of the factor are Yes and No.\nNeither of these variables display any missing values within our sample, so we have a complete set of 201 movies.\n\n\n\n\n\n\nWhat is our design?\n\n\n\nThis Analysis 2 is about comparing two means with independent samples. You should be able to explain, in a clear English sentence or two, why your data were gathered using an independent-samples design. I’ll leave that to you, but it’s very important.\n\n\n\n\n\n\n\n\nWhat to do about missing data\n\n\n\nIn Project A, I would begin Analysis 2 by filtering to complete cases if I had missing values, and thus make a statement that you are assuming the appropriate missing data mechanism in that instance. I would not impute for Analysis 2.\nIf you don’t have missing values in the variables used in this analysis, there is no reason to specify a missing data mechanism or do any filtering or imputation."
  },
  {
    "objectID": "431-movies-analysis2.html#summaries",
    "href": "431-movies-analysis2.html#summaries",
    "title": "Your Favorite Movies: Analysis 2",
    "section": "6.2 Summaries",
    "text": "6.2 Summaries\n\n6.2.1 Distribution of the Outcome within Predictor Groups\nHere is a box and violin plot of the data, which is probably the most likely starting plot. Here we see that each of the distributions is somewhat left-skewed, with the mean well below the median.\n\nggplot(movies2, aes(x = imdb_stars, y = dr_love)) +\n  geom_violin(fill = cwru_lightgray) +\n  geom_boxplot(width = 0.3, fill = cwru_lightblue, notch = TRUE,\n               outlier.color = cwru_blue, outlier.size = 3) +\n  stat_summary(fun = \"mean\", geom = \"point\", shape = 23, size = 3, \n               fill = cwru_blue) +\n  labs(x = \"IMDB Stars\", y = \"Has Dr. Love seen movie?\",\n       title = \"Favorite Movies Sample for Fall 2023\")\n\n\n\n\nThe movies Dr. Love has seen seem to have a somewhat higher median and mean IMDB score than the movies he has not, within our sample.\nAs we saw in Analysis 1, several of these movies are identified here as low outliers in terms of their IMDB Stars. Here’s the set of films with the five lowest IMDB star ratings in our sample.\n\nmovies2 |&gt; arrange(imdb_stars) |&gt; head(5)\n\n# A tibble: 5 × 4\n  film_id film                  imdb_stars dr_love\n  &lt;chr&gt;   &lt;chr&gt;                      &lt;dbl&gt; &lt;fct&gt;  \n1 61      The Gingerdead Man           3.4 No     \n2 163     The Room                     3.6 Yes    \n3 115     Madea Goes To Jail           4.5 No     \n4 78      High School Musical 2        5.2 No     \n5 83      House Party 2                5.3 No     \n\n\nWe could also fit a pair of Normal Q-Q plots to describe the two groups (movies Dr. Love has seen and those he hasn’t), if that was helpful in some substantial way. I don’t know that it gives me any information I didn’t already have from the previous plot in this case. I still think that the data are substantially left-skewed in each group.\n\np1 &lt;- ggplot(\n  data = movies2 |&gt; filter(dr_love == \"Yes\"), aes(sample = imdb_stars)) +\n  geom_qq() + geom_qq_line(col = cwru_trueblue) +\n  theme(aspect.ratio = 1) + \n  labs(title = \"Movies Dr. Love has seen\", y = \"IMDB Stars\",\n       x = \"Expectation for Standard Normal\")\n\np2 &lt;- ggplot(\n  data = movies2 |&gt; filter(dr_love == \"No\"), aes(sample = imdb_stars)) +\n  geom_qq() + geom_qq_line(col = cwru_trueblue) +\n  theme(aspect.ratio = 1) + \n  labs(title = \"Movies Dr. Love hasn't seen\", y = \"IMDB Stars\", \n       x = \"Expectation for Standard Normal\")\n\np1 + p2  \n\n\n\n\n\n\n\n\n\n\nShould I consider transforming the outcome in Analysis 2?\n\n\n\nNot in Project A, no.\n\n\n\n\n6.2.2 Numerical Summaries\n\nkey2 &lt;- \n  favstats(imdb_stars ~ dr_love, data = movies2)\n\nkey2 |&gt; gt() |&gt; gt_theme_dark()\n\n\n\n\n\n  \n    \n    \n      dr_love\n      min\n      Q1\n      median\n      Q3\n      max\n      mean\n      sd\n      n\n      missing\n    \n  \n  \n    No\n3.4\n7.0\n7.6\n8.0\n8.7\n7.420161\n0.8360748\n124\n0\n    Yes\n3.6\n7.4\n7.9\n8.4\n9.3\n7.792208\n0.9050685\n77\n0\n  \n  \n  \n\n\n\n\nAgain, we see that the “Yes” group has a higher mean and median imdb_stars value than the “No” group in our sample."
  },
  {
    "objectID": "431-movies-analysis2.html#approach",
    "href": "431-movies-analysis2.html#approach",
    "title": "Your Favorite Movies: Analysis 2",
    "section": "6.3 Approach",
    "text": "6.3 Approach\n\n6.3.1 90% CI for difference in group means via t-based procedure\nGiven the clear skew in our data, we’ll focus on the bootstrap results that follow, but for now, we can also fit a 90% CI for the difference in mean imdb_stars between the two dr_love groups while either assuming equal variances (in the population) or not.\nSince we have an unbalanced design (as we see from the unequal sample sizes below), we must make a decision here as to whether assuming equal variances is reasonable. Here, the sample variances are:\n\nmovies2 |&gt; group_by(dr_love) |&gt;\n  summarise(n = n(), var(imdb_stars))\n\n# A tibble: 2 × 3\n  dr_love     n `var(imdb_stars)`\n  &lt;fct&gt;   &lt;int&gt;             &lt;dbl&gt;\n1 No        124             0.699\n2 Yes        77             0.819\n\n\nThe variance ratio is 1.17, with the larger sample size group (Yes) associated with the larger sample variance. I’d worry about this more if the variance was at least 50% larger in one group than the other, but it’s not hard to run this either making the assumption of equal population variances or not making that assumption.\nHere’s a Welch t test approach, which does not assume equal variances.\n\nt.test(imdb_stars ~ dr_love, data = movies2, \n       conf.int = TRUE, conf.level = 0.90) |&gt;\n  tidy() |&gt; \n  gt() |&gt; fmt_number(columns = where(is.numeric), decimals = 3) |&gt; \n  gt_theme_espn()\n\n\n\n\n\n  \n    \n    \n      estimate\n      estimate1\n      estimate2\n      statistic\n      p.value\n      parameter\n      conf.low\n      conf.high\n      method\n      alternative\n    \n  \n  \n    −0.372\n7.420\n7.792\n−2.916\n0.004\n151.586\n−0.583\n−0.161\nWelch Two Sample t-test\ntwo.sided\n  \n  \n  \n\n\n\n\nHere’s a two-sample t test approach which does assume equal variances.\n\nt.test(imdb_stars ~ dr_love, data = movies2, var.equal = TRUE,\n       conf.int = TRUE, conf.level = 0.90) |&gt;\n  tidy() |&gt; \n  gt() |&gt; fmt_number(columns = where(is.numeric), decimals = 3) |&gt; \n  gt_theme_excel()\n\n\n\n\n\n  \n    \n    \n      estimate\n      estimate1\n      estimate2\n      statistic\n      p.value\n      parameter\n      conf.low\n      conf.high\n      method\n      alternative\n    \n  \n  \n    −0.372\n7.420\n7.792\n−2.971\n0.003\n199.000\n−0.579\n−0.165\nTwo Sample t-test\ntwo.sided\n  \n  \n  \n\n\n\n\nAn equivalent way to get the “equal variances” 90% confidence interval result follows.\n\nm3 &lt;- lm(imdb_stars ~ dr_love, data = movies2)\n\ntidy(m3, conf.int = TRUE, conf.level = 0.90) |&gt; \n  gt() |&gt; fmt_number(columns = where(is.numeric), decimals = 3) |&gt; \n  gt_theme_excel()\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n7.420\n0.078\n95.736\n0.000\n7.292\n7.548\n    dr_loveYes\n0.372\n0.125\n2.971\n0.003\n0.165\n0.579\n  \n  \n  \n\n\n\n\n\n\n6.3.2 90% CI for difference in group means via bootstrap\nIn our setting, given the clear skew in the imdb_stars values within each of our groups (movies Dr. Love has and hasn’t seen), we will want to focus on a bootstrap 90% confidence interval for the difference in means. We’ll stick to a percentile bootstrap here.\n\nset.seed(4312023)\nbootdif(movies2$imdb_stars, movies2$dr_love, conf.level = 0.90, B.reps = 2000)\n\nMean Difference            0.05            0.95 \n      0.3720465       0.1572827       0.5764050 \n\n\nOur 90% bootstrap confidence interval for the difference in population means (Yes - No) in imdb_stars is (0.157, 0.576) with a point estimate of 0.372. I suppose the question now is whether or not this would be considered a meaningful difference in average imdb_stars.\n\n\n\n\n\n\nNote\n\n\n\nAs the instructions suggest, you should show your work and your reasoning (not just your code), and comment on any analytic decisions you make. Be sure to actively present and justify any assumptions you are making."
  },
  {
    "objectID": "431-movies-analysis2.html#conclusions",
    "href": "431-movies-analysis2.html#conclusions",
    "title": "Your Favorite Movies: Analysis 2",
    "section": "6.4 Conclusions",
    "text": "6.4 Conclusions\n\n\n\n\n\n\nNote\n\n\n\nAgain, I’ll just reprint the Advice on Analysis 2 Conclusions from the Instructions…\n\n\nFor Analysis 2, you’ll write two paragraphs.\nIn the first paragraph, you should provide a clear restatement of your research question, followed by a clear and appropriate response to your research question, motivated by your results. Interpret your 90% confidence interval’s endpoints and width in context.\nThen, write a paragraph which summarizes the key limitations of your work in Analysis 2.\n\nIf you see problems with the assumptions behind your choice of interval, that would be a good thing to talk about here, for instance.\nAnother issue that is worth discussing is your target population, and what evidence you can describe that might indicate whether your selected states are a representative sample of the US as a whole, or perhaps some particular part of the United States.\nYou should also provide at least one useful “next step” that you could take to improve this analysis (just saying “get more data” isn’t a sufficient next step.)"
  },
  {
    "objectID": "431-movies-analysis3.html",
    "href": "431-movies-analysis3.html",
    "title": "Your Favorite Movies: Analysis 3",
    "section": "",
    "text": "library(Hmisc)\nlibrary(janitor)\nlibrary(naniar)\n\nlibrary(xfun) ## or, if you prefer use library(sessioninfo)\n\nlibrary(googlesheets4)\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(mosaic)\n\nlibrary(broom)\nlibrary(patchwork)\n\nlibrary(tidyverse)\n\ntheme_set(theme_bw())\nknitr::opts_chunk$set(comment = NA)"
  },
  {
    "objectID": "431-movies-analysis3.html#variables",
    "href": "431-movies-analysis3.html#variables",
    "title": "Your Favorite Movies: Analysis 3",
    "section": "6.1 Variables",
    "text": "6.1 Variables\nHere our key variables include two measures of a quantitative outcome, which we will combine to form a paired difference. We are interested in understanding something about the difference in percentages with favorable ratings comparing professional critics to the general audience.\nOur outcomes are shown in the rt_critics and rt_audience variables, each of which expresses the percentage of people in that group who described the movie favorably.\nWe needed to deal with the missing values of rt_critics for a couple of the movies which had fewer than 10 critic reviews, according to the Rotten Tomatoes site. So, immediately after importing the data, I filtered to the 53 movies with complete data on all four variables included in movies3.\n\n\n\n\n\n\nWhat to do about missing data\n\n\n\nIn Project A, I would begin Analysis 3 by filtering to complete cases (as I have) and then make a statement about what you are assuming the appropriate missing data mechanism to be (which I haven’t, here.) I would not impute for Analysis 3.\nIf you don’t have missing values in the variables used in this analysis, there is no reason to specify a missing data mechanism or do any filtering or imputation.\n\n\nOur sample therefore consists of the 55 movies with complete data on rt_critics and rt_audience, all of whom were also mentioned by at least one Fall 2023 student.\n\n\n\n\n\n\nWhat is our design?\n\n\n\nThis Analysis 3 is about comparing two means with paired samples. You should be able to explain, in a clear English sentence or two, why your data were gathered using an paired-samples design. I’ll leave that to you, but it’s very important."
  },
  {
    "objectID": "431-movies-analysis3.html#summaries",
    "href": "431-movies-analysis3.html#summaries",
    "title": "Your Favorite Movies: Analysis 3",
    "section": "6.2 Summaries",
    "text": "6.2 Summaries\n\n6.2.1 Distribution of the Paired Differences\nFirst, we’ll create the paired differences as rt_audience - rt_critics.\n\nmovies3_cc &lt;- movies3_cc |&gt; mutate(dif = rt_audience - rt_critics)\n\nNext, we’ll assess the distribution of those paired differences with our usual set of plots.\n\n## Normal Q-Q plot\np1 &lt;- ggplot(movies3_cc, aes(sample = dif)) +\n  geom_qq(col = cwru_blue, size = 2) + geom_qq_line(col = cwru_trueblue) +\n  theme(aspect.ratio = 1) + \n  labs(title = \"Normal Q-Q plot\",\n       y = \"Audience - Critics Response\",\n       x = \"Expectation under Standard Normal\")\n\n## Histogram with Normal density superimposed\np2 &lt;- ggplot(movies3_cc, aes(dif)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 7, fill = cwru_blue, col = cwru_lightgray) +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(movies3_cc$dif, na.rm = TRUE), \n                            sd = sd(movies3_cc$dif, na.rm = TRUE)),\n                col = cwru_darkgray, lwd = 1.5) +\n  labs(title = \"Histogram with Normal Density\",\n       x = \"Audience - Critics Response\")\n\n## Boxplot with notch and rug\np3 &lt;- ggplot(movies3_cc, aes(x = dif, y = \"\")) +\n  geom_boxplot(fill = cwru_blue, notch = TRUE, \n               outlier.color = cwru_blue, outlier.size = 2) + \n  stat_summary(fun = \"mean\", geom = \"point\", \n               shape = 23, size = 3, fill = cwru_lightgray) +\n  geom_rug(sides = \"b\") +\n  labs(title = \"Boxplot with Notch and Rug\",\n       x = \"Audience - Critics Response\",\n       y = \"\")\n\np1 + (p2 / p3 + plot_layout(heights = c(4,1))) +\n  plot_annotation(title = \"Audience - Critics % Favorable\",\n                  subtitle = str_glue(\"Fall 2023 Favorite Movies: (n = \", \n                                      nrow(movies3_cc), \")\"),\n      caption = str_glue(\"Paired Differences: Sample Size = \", nrow(movies3_cc), \n                         \", Sample Median = \", round_half_up(median(movies3_cc$dif),2),\n                         \", Mean = \", round_half_up(mean(movies3_cc$dif),2), \n                         \" and SD = \", round_half_up(sd(movies3_cc$dif),2)))\n\n\n\n\nThis distribution looks to be centered very close to zero. This suggests that, on average, the ratings by critics and the ratings by the general audience might be similar.\n\n\n\n\n\n\nI’m leaving the decision about Normality to you.\n\n\n\nHere would be a smart place to describe whether or not these data can be assumed to come from a Normally distributed population.\n\n\nHere are the movies with the five highest and five lowest paired (audience - critics) differences in ratings in our sample.\n\nmovies3_cc |&gt; arrange(dif) |&gt; head(5)\n\n# A tibble: 5 × 5\n  film_id film                               rt_critics rt_audience   dif\n  &lt;chr&gt;   &lt;chr&gt;                                   &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 76      Hereditary                                 90          70   -20\n2 186     Titanic                                    88          69   -19\n3 124     Mean Girls                                 84          66   -18\n4 128     Mission Impossible: Ghost Protocol         93          76   -17\n5 37      Crazy Rich Asians                          91          76   -15\n\nmovies3_cc |&gt; arrange(dif) |&gt; tail(5)\n\n# A tibble: 5 × 5\n  film_id film                                      rt_critics rt_audience   dif\n  &lt;chr&gt;   &lt;chr&gt;                                          &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 136     National Lampoon's Christmas Vacation             70          86    16\n2 146     Pirates of the Caribbean: Dead Man's Che…         53          72    19\n3 106     The Little Mermaid (2023)                         67          94    27\n4 118     A Man Called Otto                                 70          97    27\n5 44      Divergent                                         41          69    28\n\n\n\n\n\n\n\n\nShould I consider transforming the outcome in Analysis 3?\n\n\n\nNot in Project A, no.\n\n\n\n\n6.2.2 Did pairing help reduce nuisance variation?\nThe best way to see this is with a scatterplot of the original data, where we hope to see a strong positive correlation.\n\nggplot(movies3_cc, aes(x = rt_critics, y = rt_audience)) +\n  geom_point(col = \"black\") +\n  geom_smooth(method = \"lm\", col = cwru_trueblue, formula = y ~ x, se = TRUE) +\n  geom_smooth(method = \"loess\", col = cwru_darkblue, formula = y ~ x, se = FALSE) +\n  labs(x = \"Audience: % favorable\", y = \"Critics: % favorable\",\n       title = \"Favorite Movies Sample for Fall 2023\",\n       caption = str_glue(\"Pearson correlation = \", \n                          round_half_up(cor(movies3_cc$rt_critics, \n                                            movies3_cc$rt_audience), 3)),\n       subtitle = \"Strong positive relationship between Audience and Critic ratings\")\n\n\n\n\nWe see a strong, positive Pearson correlation (0.71) between the audience and critic ratings, so we conclude that pairing was helpful in this setting to reduce nuisance variation caused by differences between the quality of the individual movies in the sample.\n\n\n6.2.3 Numerical Summaries\nHere are numerical summaries of the distributions of the paired differences, as well as each of the original samples.\n\nkey3 &lt;- bind_rows(\n  favstats(~ dif, data = movies3_cc),\n  favstats(~ rt_audience, data = movies3_cc),\n  favstats(~ rt_critics, data = movies3_cc)) |&gt;\n  mutate(group = c(\"A-C difference\", \"rt_audience\", \"rt_critics\")) |&gt;\n  relocate(group)\n\nkey3 |&gt; gt() |&gt; gt_theme_dark()\n\n\n\n\n\n  \n    \n    \n      group\n      min\n      Q1\n      median\n      Q3\n      max\n      mean\n      sd\n      n\n      missing\n    \n  \n  \n    A-C difference\n-20\n-5\n0\n6\n28\n0.8679245\n10.96329\n53\n0\n    rt_audience\n45\n73\n87\n93\n98\n82.9433962\n13.23663\n53\n0\n    rt_critics\n41\n73\n88\n93\n100\n82.0754717\n15.15795\n53\n0\n  \n  \n  \n\n\n\n\nThe mean audience-critics difference in ratings is just barely positive.\n\n\n\n\n\n\nNote\n\n\n\nNote that the mean of the paired differences is the same as the difference of the means for audience and critic responses, but this isn’t true for other summary statistics."
  },
  {
    "objectID": "431-movies-analysis3.html#approach",
    "href": "431-movies-analysis3.html#approach",
    "title": "Your Favorite Movies: Analysis 3",
    "section": "6.3 Approach",
    "text": "6.3 Approach\n\n6.3.1 90% CI for mean of paired differences via t-based procedure\nHere’s the t-based result, which is appropriate if we believe the paired differences can be assumed to come from a Normal population.\n\nm3 &lt;- lm(dif ~ 1, data = movies3_cc)\n\ntidy(m3, conf.int = TRUE, conf.level = 0.90) |&gt; \n  gt() |&gt; fmt_number(columns = where(is.numeric), decimals = 3) |&gt;\n  gt_theme_nytimes()\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n      conf.low\n      conf.high\n    \n  \n  \n    (Intercept)\n0.868\n1.506\n0.576\n0.567\n−1.654\n3.390\n  \n  \n  \n\n\n\n\n\n\n6.3.2 90% CI for mean of paired differences via bootstrap\nHere’s the bootstrap result, which is more appropriate than the t procedure if we believe the paired differences cannot be assumed to come from a Normal population.\n\nset.seed(4312023)\nsmean.cl.boot(movies3_cc$dif, conf.int = 0.90, B = 2000)\n\n      Mean      Lower      Upper \n 0.8679245 -1.6047170  3.3773585 \n\n\n\n\n\n\n\n\nNote\n\n\n\nAs the instructions suggest, you should show your work and your reasoning (not just your code), and comment on any analytic decisions you make. Be sure to actively present and justify any assumptions you are making.\nI’ve also left it to you to build appropriate interpretations of these confidence interval estimates."
  },
  {
    "objectID": "431-movies-analysis3.html#conclusions",
    "href": "431-movies-analysis3.html#conclusions",
    "title": "Your Favorite Movies: Analysis 3",
    "section": "6.4 Conclusions",
    "text": "6.4 Conclusions\n\n\n\n\n\n\nNote\n\n\n\nI’ll just reprint the Advice on Analysis 3 Conclusions from the Instructions\n\n\nFor Analysis 3, you’ll write two paragraphs.\nIn the first paragraph, you should provide a clear restatement of your research question, followed by a clear and appropriate response to your research question, motivated by your results. Interpret your chosen 90% confidence interval’s endpoints and width in context. You should also reflect on your pre-existing belief about what would happen, (as discussed in Section 12) in light of your results.\nThen, write a paragraph which summarizes the key limitations of your work in Analysis 3.\n\nIf you see problems with the assumptions behind your choice of interval, that would be a good thing to talk about here, for instance.\nIf pairing didn’t “help” (in the sense that there was no substantial positive correlation between the 2018 and 2023 reports), that would be worth discussing here.\nAnother issue that is worth discussing is your target population, and what evidence you can describe that might indicate whether your selected states are a representative sample of the US as a whole, or perhaps some particular part of the United States.\nYou should also provide at least one useful “next step” that you could take to improve this analysis (just saying “get more data” isn’t a sufficient next step.)"
  },
  {
    "objectID": "analyses.html",
    "href": "analyses.html",
    "title": "Project A Analyses",
    "section": "",
    "text": "Using the tibble you’ve developed following the instructions on the Data and Proposal pages, you will perform three analyses, as specified below. Your final portfolio report will include:\n\nSections 1-12 from the Proposal, edited as necessary.\nSection 13 will be your Analysis 1, and will have four subsections.\nSection 14 will be your Analysis 2, with four subsections.\nSection 15 will be your Analysis 3, with four subsections.\nSection 16 will be a new Reflections section, discussed in the Portfolio materials.\nSection 17 will be your new location for session information.\n\nThe four subsections for each Analysis are to be labeled:\n\nVariables\nSummaries\nApproach\nConclusions\n\n\n\nFor each of the three Analyses, you will start by re-specifying the variables you are studying, including appropriate units of measurement, and briefly remind us about how your sample was developed, including information on the total number of counties involved in this Analysis, specifying which states are used, and whether any relevant data are missing. Be sure to edit your data management and Codebook in sections from your Proposal to accurately describe all variables you are using in your analyses. In particular, no additional adjustments to your tibble should be made after section 8 in your portfolio report.\nIn proposal section 12, you stated the research question you are trying to answer with each analysis. You should also indicate in that section your pre-data collection belief about what conclusion you would draw. In developing your final portfolio report, you should edit these statements (as necessary) to reflect the Analyses you’ve actually done.\n\n\n\nHere, you will provide numerical summaries and visualizations of interest that are relevant to your analysis, and comment on any issues you observe. All of your plots should be attractive and well-labeled, and (when possible) use ggplot tools. Specific suggestions about necessary data descriptions for each Analysis are discussed below.\n\n\n\nEach Analysis should, of course, include all of the R code you used to create your work, and complete English sentences that interpret your results. Your work must demonstrate that you are able to reason about what you’ve done, not just generate the code which works to create results. Here, you will:\n\nAssess which of several options for modeling (Analysis 1) or creating an inference (Analyses 2 and 3) is most appropriate, with the help of useful diagnostics.\nComplete any specialized analytic requirements (as discussed below) unique to that Analysis, and obtain results which allow you to address your research question.\n\n\n\n\nYou will write a two-paragraph conclusions section for each Analysis.\n\nThe first paragraph should provide a clear restatement of your research question, followed by a clear response to that question, motivated by your results. Remember that a research question will end with a question mark, and will be something you will be able to answer (or at least respond to effectively) after your analysis is complete. You should also reflect on your pre-existing belief about what would happen, (as discussed in Section 12) in light of the data.\nThe second paragraph should summarize the key limitations of your Analysis, and opportunities for useful next steps associated with that Analysis. To be clear, just writing “get more data,” though generally good advice, isn’t a sufficient next step. Also, note that it’s not a good idea to suggest limitations that you could fix with the tools you have - instead, apply those tools and build a better Analysis."
  },
  {
    "objectID": "analyses.html#subsection-1.-variables",
    "href": "analyses.html#subsection-1.-variables",
    "title": "Project A Analyses",
    "section": "",
    "text": "For each of the three Analyses, you will start by re-specifying the variables you are studying, including appropriate units of measurement, and briefly remind us about how your sample was developed, including information on the total number of counties involved in this Analysis, specifying which states are used, and whether any relevant data are missing. Be sure to edit your data management and Codebook in sections from your Proposal to accurately describe all variables you are using in your analyses. In particular, no additional adjustments to your tibble should be made after section 8 in your portfolio report.\nIn proposal section 12, you stated the research question you are trying to answer with each analysis. You should also indicate in that section your pre-data collection belief about what conclusion you would draw. In developing your final portfolio report, you should edit these statements (as necessary) to reflect the Analyses you’ve actually done."
  },
  {
    "objectID": "analyses.html#subsection-2.-summaries",
    "href": "analyses.html#subsection-2.-summaries",
    "title": "Project A Analyses",
    "section": "",
    "text": "Here, you will provide numerical summaries and visualizations of interest that are relevant to your analysis, and comment on any issues you observe. All of your plots should be attractive and well-labeled, and (when possible) use ggplot tools. Specific suggestions about necessary data descriptions for each Analysis are discussed below."
  },
  {
    "objectID": "analyses.html#subsection-3.-approach",
    "href": "analyses.html#subsection-3.-approach",
    "title": "Project A Analyses",
    "section": "",
    "text": "Each Analysis should, of course, include all of the R code you used to create your work, and complete English sentences that interpret your results. Your work must demonstrate that you are able to reason about what you’ve done, not just generate the code which works to create results. Here, you will:\n\nAssess which of several options for modeling (Analysis 1) or creating an inference (Analyses 2 and 3) is most appropriate, with the help of useful diagnostics.\nComplete any specialized analytic requirements (as discussed below) unique to that Analysis, and obtain results which allow you to address your research question."
  },
  {
    "objectID": "analyses.html#subsection-4.-conclusions",
    "href": "analyses.html#subsection-4.-conclusions",
    "title": "Project A Analyses",
    "section": "",
    "text": "You will write a two-paragraph conclusions section for each Analysis.\n\nThe first paragraph should provide a clear restatement of your research question, followed by a clear response to that question, motivated by your results. Remember that a research question will end with a question mark, and will be something you will be able to answer (or at least respond to effectively) after your analysis is complete. You should also reflect on your pre-existing belief about what would happen, (as discussed in Section 12) in light of the data.\nThe second paragraph should summarize the key limitations of your Analysis, and opportunities for useful next steps associated with that Analysis. To be clear, just writing “get more data,” though generally good advice, isn’t a sufficient next step. Also, note that it’s not a good idea to suggest limitations that you could fix with the tools you have - instead, apply those tools and build a better Analysis."
  },
  {
    "objectID": "analyses.html#advice-on-variables",
    "href": "analyses.html#advice-on-variables",
    "title": "Project A Analyses",
    "section": "2.1 Advice on Variables",
    "text": "2.1 Advice on Variables\nIn this section you will build a simple linear regression model to predict your Analysis 1 outcome using your Analysis 1 predictor. Start by identifying those variables, and by restricting your data set for this analysis to the complete cases on those variables.\n\nUse complete English sentences to identify your outcome and your predictor, describing what each variable means and its units of measurement.\nAlso specify how many counties have complete data on both variables.\nFinally, specify the values of your outcome and predictor for Cuyahoga County, in Ohio, where CWRU’s campus is located."
  },
  {
    "objectID": "analyses.html#advice-on-summaries",
    "href": "analyses.html#advice-on-summaries",
    "title": "Project A Analyses",
    "section": "2.2 Advice on Summaries",
    "text": "2.2 Advice on Summaries\nYou will need to build a visualization of the relationship between the outcome (Y-axis) and the predictor (X-axis) and a written description of what you learn about the association (which should include comments about its direction, shape and strength along with identification of any substantial outliers).\nYou will need to address the possibility of a transformation here:\n\nA specification of any transformations you choose to apply to the X or Y variable in order to obtain a better fit with a simple linear regression, along with some justification for the choice (or for the decision not to apply a transformation.)\n\nFor this part of Project A, confine your search to either a logarithm, an inverse, or a square as applied to the outcome. If you want to consider one of those transformations for the predictor as well, that’s OK but not crucial.\nYou should select the most promising transformation on the basis of a scatterplot (perhaps with a loess smooth and linear fit) after the transformation has been applied. You are permitted but not required to use the Box-Cox approach to help here.\n\n\nIf you decide to use a transformation with either the outcome or predictor before fitting your final model, you should display two plots: one with and one without that transformation. Your plot (including the transformation, if you use one) should include both a loess smooth and the regression line from your final linear model."
  },
  {
    "objectID": "analyses.html#advice-on-approach",
    "href": "analyses.html#advice-on-approach",
    "title": "Project A Analyses",
    "section": "2.3 Advice on Approach",
    "text": "2.3 Advice on Approach\nFit your model to use your predictor to predict your outcome (applying your selected transformation) and provide the code you used, and the following summary elements in this section.\n\nA written statement of the full prediction equation, with coefficients nicely rounded, and a careful description of what the coefficients mean in context. If you’re using a transformation of the outcome or the predictor, be sure this is reflected in your comments here.\nA tidy summary of the model’s coefficients, including 90% confidence interval for model estimates.\nThe model’s R-squared, residual standard error, and the number of observations to which the model was fit.\n\n\n2.3.1 Residual Analysis\nAt the end of your Approach section for Analysis 1, you’ll need to:\n\nprepare a pair of residual plots (one to assess residuals vs. fitted values for non-linearity, and one to assess Normality in the residuals or the standardized residuals.)\n\nIf you model is called m1, you could use something like plot(m1, which = c(1:2)) to obtain these two plots and that’s OK, although a ggplot-based alternative using patchwork would be even nicer.\n\ninterpret the residual plots in terms of what they tell you about how well the assumptions of linearity and Normality hold for your setting, in complete English sentences.\ndisplay your model’s prediction for the original (untransformed) outcome you are studying for Cuyahoga County, in Ohio, and compare it to Cuyahoga’s actual value of this outcome.\nidentify the two counties (by name and state) where the model you’ve fit is least successful at predicting the outcome (in the sense of having the largest residual in absolute value.)"
  },
  {
    "objectID": "analyses.html#advice-on-conclusions",
    "href": "analyses.html#advice-on-conclusions",
    "title": "Project A Analyses",
    "section": "2.4 Advice on Conclusions",
    "text": "2.4 Advice on Conclusions\nFor Analysis 1, you’ll write two paragraphs.\nIn the first paragraph, you should provide a clear restatement of your research question, followed by a clear and appropriate response to your research question, motivated by your results. Most of the time, one model won’t let you come to a strong conclusion about a question of interest, and it is your job to accurately present what information can be specified as a result of the model, without overstating your conclusions.\nThen, write a paragraph which summarizes the key limitations of your work in Analysis 1.\n\nIf you see problems with regression assumptions in your residual plot, that would be a good thing to talk about here, for instance.\nAnother issue that is worth discussing is your target population, and what evidence you can describe that might indicate whether your selected states are a representative sample of the US as a whole, or perhaps some particular part of the United States.\nYou should also provide at least one useful “next step” that you could take to improve this analysis (just saying “get more data” isn’t a sufficient next step.)"
  },
  {
    "objectID": "analyses.html#advice-on-variables-1",
    "href": "analyses.html#advice-on-variables-1",
    "title": "Project A Analyses",
    "section": "3.1 Advice on Variables",
    "text": "3.1 Advice on Variables\nHere, you have identified one quantitative (Analysis 2 outcome) and one categorical variable (Analysis 2 binary predictor.)\n\nUse complete English sentences to identify your outcome and your predictor, describing what each variable means and its units of measurement.\nAlso specify how many counties have complete data on both variables.\nFinally, specify the values of your outcome and predictor for Cuyahoga County, in Ohio, where CWRU’s campus is located."
  },
  {
    "objectID": "analyses.html#advice-on-summaries-1",
    "href": "analyses.html#advice-on-summaries-1",
    "title": "Project A Analyses",
    "section": "3.2 Advice on Summaries",
    "text": "3.2 Advice on Summaries\nHere, prepare descriptive summaries of the data across the two predictor groups for your chosen outcome, including, of course, attractive and well-constructed visualizations which can be used for comparisons.\nA comparison boxplot with violins is an excellent option here for the key visualization. Be sure to label it carefully, and use color and/or fill wisely to create a clear and attractive picture."
  },
  {
    "objectID": "analyses.html#advice-on-approach-1",
    "href": "analyses.html#advice-on-approach-1",
    "title": "Project A Analyses",
    "section": "3.3 Advice on Approach",
    "text": "3.3 Advice on Approach\nYou’ll analyze the results and build a 90% confidence interval for the difference in group means with an appropriate t-based procedure, and with a bootstrap procedure.\nYou’ll then select one of these two procedures to provide your final response, and discuss the reasons behind the choice you made.\nShow your work and your reasoning (not just your code), and comment on any analytic decisions you make. Be sure to actively present and justify any assumptions you are making."
  },
  {
    "objectID": "analyses.html#advice-on-conclusions-1",
    "href": "analyses.html#advice-on-conclusions-1",
    "title": "Project A Analyses",
    "section": "3.4 Advice on Conclusions",
    "text": "3.4 Advice on Conclusions\nFor Analysis 2, you’ll write two paragraphs.\nIn the first paragraph, you should provide a clear restatement of your research question, followed by a clear and appropriate response to your research question, motivated by your results. Interpret your 90% confidence interval’s endpoints and width in context.\nThen, write a paragraph which summarizes the key limitations of your work in Analysis 2.\n\nIf you see problems with the assumptions behind your choice of interval, that would be a good thing to talk about here, for instance.\nAnother issue that is worth discussing is your target population, and what evidence you can describe that might indicate whether your selected states are a representative sample of the US as a whole, or perhaps some particular part of the United States.\nYou should also provide at least one useful “next step” that you could take to improve this analysis (just saying “get more data” isn’t a sufficient next step.)"
  },
  {
    "objectID": "analyses.html#advice-on-variables-2",
    "href": "analyses.html#advice-on-variables-2",
    "title": "Project A Analyses",
    "section": "4.1 Advice on Variables",
    "text": "4.1 Advice on Variables\nHere, we have identified two quantitative variables (the same outcome in two different time periods) which are paired (so that they have a natural link between them, and use the same units of measurement.)\n\nYour Analysis 3 material should start with specifications of what the outcome you are studying in this analysis actually means, including its units, and how your samples in 2018 and 2023 were created."
  },
  {
    "objectID": "analyses.html#advice-on-summaries-2",
    "href": "analyses.html#advice-on-summaries-2",
    "title": "Project A Analyses",
    "section": "4.2 Advice on Summaries",
    "text": "4.2 Advice on Summaries\nProvide numerical summaries and visualizations of interest that are relevant to this analysis, and comment on any issues you observe.\nThe natural choice is a boxplot with violin for the paired differences, along with a Normal Q-Q plot of those paired differences. Be sure to remind us how many “pairs” of values you have to work with in your labels for these plots.\nYou will need to provide some evidence on how well the “pairing” worked in this setting, by interpreting the Pearson correlation between the 2018 and 2023 values."
  },
  {
    "objectID": "analyses.html#advice-on-approach-2",
    "href": "analyses.html#advice-on-approach-2",
    "title": "Project A Analyses",
    "section": "4.3 Advice on Approach",
    "text": "4.3 Advice on Approach\nYou’ll analyze the results and build a 90% confidence interval for the population mean difference with an appropriate t-based procedure, and an appropriate bootstrap procedure.\nYou’ll then select one of these two procedures to provide your final response, and discuss the reasons behind the choice you made.\nShow your work and your reasoning (not just your code), and comment on any analytic decisions you make. Be sure to actively present and justify any assumptions you are making."
  },
  {
    "objectID": "analyses.html#advice-on-conclusions-2",
    "href": "analyses.html#advice-on-conclusions-2",
    "title": "Project A Analyses",
    "section": "4.4 Advice on Conclusions",
    "text": "4.4 Advice on Conclusions\nFor Analysis 3, you’ll write two paragraphs.\nIn the first paragraph, you should provide a clear restatement of your research question, followed by a clear and appropriate response to your research question, motivated by your results. Interpret your chosen 90% confidence interval’s endpoints and width in context. You should also reflect on your pre-existing belief about what would happen, (as discussed in Section 12) in light of your results.\nThen, write a paragraph which summarizes the key limitations of your work in Analysis 3.\n\nIf you see problems with the assumptions behind your choice of interval, that would be a good thing to talk about here, for instance.\nIf pairing didn’t “help” (in the sense that there was no substantial positive correlation between the 2018 and 2023 reports), that would be worth discussing here.\nAnother issue that is worth discussing is your target population, and what evidence you can describe that might indicate whether your selected states are a representative sample of the US as a whole, or perhaps some particular part of the United States.\nYou should also provide at least one useful “next step” that you could take to improve this analysis (just saying “get more data” isn’t a sufficient next step.)"
  },
  {
    "objectID": "cleaning.html",
    "href": "cleaning.html",
    "title": "Cleaning Your Variables",
    "section": "",
    "text": "This page was last updated: 2023-10-19 12:37:06.972379.\nCheck your five variables on the lists below. You should find all five."
  },
  {
    "objectID": "cleaning.html#variables-that-are-proportions-should-be-converted-to-percentages",
    "href": "cleaning.html#variables-that-are-proportions-should-be-converted-to-percentages",
    "title": "Cleaning Your Variables",
    "section": "1 Variables that are Proportions should be converted to Percentages",
    "text": "1 Variables that are Proportions should be converted to Percentages\nEach of the variables listed below are proportions (between 0 and 1). Before you use them in any analyses, we encourage you strongly to multiply them by 100 in your data development (using mutate) to turn their values into percentages (between 0 and 100) and this will seriously ease the interpretation of slopes and transformations for these variables.\n\n\n\nCode\nVariable Description\n\n\n\n\nv002\nPoor or fair health\n\n\nv003\nUninsured adults (pick v003 or v085, but not both)\n\n\nv009\nAdult smoking\n\n\nv011\nAdult obesity\n\n\nv021\nHigh school graduation\n\n\nv023\nUnemployment\n\n\nv024\nChildren in poverty\n\n\nv037\nLow birthweight\n\n\nv049\nExcessive drinking\n\n\nv052\nProportion below 18 years of age\n\n\nv057\nProportion Females\n\n\nv058\nProportion Rural\n\n\nv059\nProportion not proficient in English\n\n\nv060\nDiabetes prevalence\n\n\nv067\nDriving alone to work\n\n\nv069\nSome college\n\n\nv070\nPhysical inactivity\n\n\nv082\nChildren in single-parent households\n\n\nv083\nLimited access to healthy foods\n\n\nv085\nUninsured (pick v003 or v085, but not both)\n\n\nv122\nUninsured children (pick v085 or v122, but not both)\n\n\nv132\nAccess to exercise opportunities\n\n\nv136\nSevere housing problems\n\n\nv139\nFood insecurity\n\n\nv143\nInsufficient sleep\n\n\nv144\nFrequent physical distress (pick v036 or v144, but not both)\n\n\nv145\nFrequent mental distress (pick v042 or v145, but not both)\n\n\nv153\nHomeownership\n\n\nv155\nFlu vaccinations"
  },
  {
    "objectID": "cleaning.html#ratios-that-need-converting",
    "href": "cleaning.html#ratios-that-need-converting",
    "title": "Cleaning Your Variables",
    "section": "2 Ratios That Need Converting",
    "text": "2 Ratios That Need Converting\nThese two variables are specified as providers per population in the raw data. You will want to multiply the values by 100,000 in order to providers per 100,000 population and get more interpretable results.\n\n\n\nCode\nVariable Description\n\n\n\n\nv004\nPrimary care physicians\n\n\nv062\nMental health providers"
  },
  {
    "objectID": "cleaning.html#demographics-that-need-attention",
    "href": "cleaning.html#demographics-that-need-attention",
    "title": "Cleaning Your Variables",
    "section": "3 Demographics that need attention",
    "text": "3 Demographics that need attention\n\n\n\n\n\n\n\n\nCode\nVariable Description\nWhat to do?\n\n\n\n\nv001\nPremature death\nConsider dividing by 100 to represent losses per 1000 population\n\n\nv063\nMedian household income\nDivide by 1000 to represent in thousands of dollars\n\n\nv051\nPopulation\nEither use log10(population), or divide population by 1000 to represent population in thousands."
  },
  {
    "objectID": "cleaning.html#variables-that-should-be-ok-as-is",
    "href": "cleaning.html#variables-that-should-be-ok-as-is",
    "title": "Cleaning Your Variables",
    "section": "4 Variables that should be OK as is",
    "text": "4 Variables that should be OK as is\nThe variables listed below should be fine as they are. Most of them are ratios, although a few are averages or indexes. The main issue for these variables is correctly specifying the units of measurement (note that the indexes don’t have units.)\n\n\n\n\n\n\n\nCode\nVariable Description\n\n\n\n\nv005\nPreventable hospital stays\n\n\nv014\nTeen births\n\n\nv036\nPoor physical health days (pick v036 or v144, but not both)\n\n\nv039\nMotor vehicle crash deaths\n\n\nv042\nPoor mental health days (pick v042 or v145, but not both)\n\n\nv043\nViolent crime\n\n\nv044\nIncome inequality\n\n\nv045\nSexually transmitted infections\n\n\nv125\nAir pollution - particulate matter\n\n\nv127\nPremature age-adjusted mortality\n\n\nv128\nChild mortality\n\n\nv133\nFood environment index\n\n\nv135\nInjury deaths\n\n\nv140\nSocial associations\n\n\nv141\nResidential segregation - Black/White (pick v141 or v142, not both)\n\n\nv142\nResidential segregation - non-White/White (pick v141 or v142, not both)\n\n\nv147\nLife expectancy\n\n\nv148\nFirearm fatalities\n\n\nv156\nTraffic volume\n\n\nv159\nReading scores\n\n\nv160\nMath scores\n\n\nv161\nSuicides"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Project A Data",
    "section": "",
    "text": "Important\n\n\n\nBefore starting your Data work, it’s a really good idea to read through:\n\nthis entire Data page\nthe entire Proposal page, and\nthe Examples material related to the Proposal, including the proposal template and the sample proposal.\n\nTrust us. You’ll save a lot of time and energy if you do so."
  },
  {
    "objectID": "data.html#table-a.-states-you-can-select",
    "href": "data.html#table-a.-states-you-can-select",
    "title": "Project A Data",
    "section": "4.1 Table A. States You Can Select",
    "text": "4.1 Table A. States You Can Select\nThe number of counties (with county_ranked values of 1 in CHR 2023) in each state (specified using its two-letter postal abbreviation) is listed below, for your convenience.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstate\nState  Name\nranked  counties\nstate\nState  Name\nranked  counties\nstate\nState  Name\nranked  counties\n\n\n\n\nAL\nAlabama\n67\nMD\nMaryland\n24\nOK\nOklahoma\n77\n\n\nAR\nArkansas\n75\nMI\nMichigan\n83\nOR\nOregon\n35\n\n\nCA\nCalifornia\n58\nMN\nMinnesota\n87\nPA\nPennsylvania\n67\n\n\nCO\nColorado\n59\nMO\nMissouri\n115\nSC\nSouth Carolina\n46\n\n\nFL\nFlorida\n67\nMS\nMississippi\n82\nSD\nSouth Dakota\n61\n\n\nGA\nGeorgia\n159\nMT\nMontana\n47\nTN\nTennessee\n95\n\n\nIA\nIowa\n99\nNC\nNorth Carolina\n100\nTX\nTexas\n244\n\n\nID\nIdaho\n43\nND\nNorth Dakota\n48\nUT\nUtah\n28\n\n\nIL\nIllinois\n102\nNE\nNebraska\n79\nVA\nVirginia\n133\n\n\nIN\nIndiana\n92\nNJ\nNew Jersey\n21\nWA\nWashington\n39\n\n\nKS\nKansas\n104\nNM\nNew Mexico\n32\nWI\nWisconsin\n72\n\n\nKY\nKentucky\n120\nNY\nNew York\n62\nWV\nWest Virginia\n55\n\n\nLA\nLouisiana\n64\nOH\nOhio\n88\nWY\nWyoming\n23\n\n\n\nRemember to select six states (including OH) yielding a total of 300-800 counties.\n\nFor example, one possible combination would be ID (43), OR (35), MT (47), ND (48) and WA (39) with OH (88) yielding exactly 300 counties.\nanother possibility would be GA (159), TX (244), IL (102), MN (87) and KY (120) with OH (88) yielding exactly 800 counties.\n\nAfter making your selection, and filtering the data, you should have a tibble called chr_2023 which contains all of the 300-800 counties in your six states, and 720 columns."
  },
  {
    "objectID": "data.html#variables-for-each-analysis",
    "href": "data.html#variables-for-each-analysis",
    "title": "Project A Data",
    "section": "5.1 Variables for Each Analysis",
    "text": "5.1 Variables for Each Analysis\nEach of the variables you select should be of some interest to you on its own, in terms of either providing a health outcome of interest, or potentially providing useful information about a feature of the county that might relate to that health outcome. As part of the selection process, you should be developing appropriate research questions that lead to the identification of smart measures of interest (from those available) for predictors and outcomes in our Analyses. See the Proposal page in these instructions for more on creating appropriate research questions.\nYou must select five different variables from Table B, as described below.\n\nVariable 1 will be your outcome for Analysis 1. It should be a measure describing some aspect of a community’s health, rather than a demographic characteristic. Variables listed in Table B as Analysis 1 or 2 (predictor) should not be used as outcomes for either Analysis 1 or 2. As a result, you will be choosing one of these 20 variables for your Analysis 1 outcome:\n\nv001, v002, v009, v011, v036, v042, v044, v049, v050, v060, v067, v070, v125, v127, v133, v139, v140, v143, v155, or v166\n\nVariable 2 will be your predictor for Analysis 1, so the relationship between variables 1 and 2 should be of interest to you.\n\nYou can select any of the 30 variables in Table B for your Analysis 1 predictor.\n\nVariable 3 will be your outcome for Analysis 2. Like variable 1, it should describe some aspect of a community’s health, rather than just its demographics.\n\nYou can select any of the 20 variables eligible to be your Analysis 1 outcome as your Analysis 2 outcome.\n\nVariable 4 (after you categorize it, later) will be your predictor for Analysis 2. Again, the relationship between variables 3 and 4 should be of interest.\n\nYou can select any of the 30 variables in Table B for your Analysis 2 predictor.\n\nVariable 5 is your Analysis 3 outcome, which you will compare to its 2018 value in the County Health Rankings data. This is restricted a bit more, and Table B shows 10 options for Analysis 3.\n\nThese 10 options are: v001, v009, v011, v036, v042, v049, v060, v070, v139, or v143.\n\n\nRemember that each of your five selections must be a different variable."
  },
  {
    "objectID": "data.html#information-to-help-select-and-build-a-codebook",
    "href": "data.html#information-to-help-select-and-build-a-codebook",
    "title": "Project A Data",
    "section": "5.2 Information to help select and build a codebook",
    "text": "5.2 Information to help select and build a codebook\nThe 2023 CHR Analytic Data Documentation file (PDF), and the 2023 Data Dictionary file (also PDF) are crucial here, as those are the ones that explain what the available variables mean, and how they should be labeled.\n\nIn building your codebook for the Proposal, you will also need look up each measure you select at this CHR 2023 Measures link, so now would be a good time to do that, as well."
  },
  {
    "objectID": "data.html#table-b.-variables-you-can-select",
    "href": "data.html#table-b.-variables-you-can-select",
    "title": "Project A Data",
    "section": "5.3 Table B. Variables You Can Select",
    "text": "5.3 Table B. Variables You Can Select\nYou will select five different variables from the list in Table B of variables in the CHR 2023 report.\n\n\n\n\n\n\nNote\n\n\n\n\nThe listing “v001” in Table B refers to the variable named “v001_rawvalue”, and _rawvalue should be similarly appended to each of the other variable codes.\nThere are many vXXX_rawvalue variables in the CHR data which we don’t include in the list below, for several reasons, but usually because of substantial missing data.\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nBrief Label from CHR 2023\nAnalyses\nCleaning Requirements\n\n\n\n\nv001\nPremature death\n1, 2 or 3\nDivide by 100 to represent losses per 1000 population. Don’t use v127 in same analysis.\n\n\nv002\nPoor or fair health\n1 or 2\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv009\nAdult smoking\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv011\nAdult obesity\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv023\nUnemployment\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv036\nPoor physical health days\n1, 2 or 3\nOK as is.\n\n\nv042\nPoor mental health days\n1, 2 or 3\nOK as is.\n\n\nv044\nIncome inequality\n1 or 2\nOK as is.\n\n\nv049\nExcessive drinking\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv050\nMammography screening\n1 or 2\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv053\nProportion ages 65 and older\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv057\nProportion female\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv058\nProportion rural\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv059\nProportion not proficient in English\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv060\nDiabetes prevalence\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv063\nMedian household income\n1 or 2  (predictor)\nDivide by 1000 to represent income in thousands of dollars\n\n\nv067\nDriving alone to work\n1 or 2\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv070\nPhysical inactivity\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv085\nUninsured\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv125\nAir pollution - particulate matter\n1 or 2\nOK as is.\n\n\nv126\nProportion non-hispanic white\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion. Also, see note below.\n\n\nv127\nPremature age-adjusted mortality\n1 or 2\nOK as is. Do not use in same analysis as v001.\n\n\nv133\nFood environment index\n1 or 2\nOK as is. Don’t use v139 in same analysis.\n\n\nv139\nFood insecurity\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion. Don’t use v133 in same analysis.\n\n\nv140\nSocial associations\n1 or 2\nOK as is.\n\n\nv143\nInsufficient sleep\n1, 2 or 3\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv151\nGender pay gap\n1 or 2  (predictor)\nOK as is.\n\n\nv155\nFlu vaccinations\n1 or 2\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv166\nBroadband access\n1 or 2\nMultiply by 100 to describe percentage, rather than proportion\n\n\nv168\nHigh school completion\n1 or 2  (predictor)\nMultiply by 100 to describe percentage, rather than proportion\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe variable v001 is very tempting to use an outcome. That’s OK, but be sure to consider the use of v127 as an outcome if mortality interests you. Do not use v001 and v127 in the same Analysis.\nA serious look at the impact of race/ethnicity is beyond the scope of Project A. If you are interested in studying race and ethnicity and their impact on a health outcome, we suggest using v126, (or its inverse, 1 - v126), to incorporate this dimension as a predictor. This is because there’s more variation in the v126 data across the reported counties than other variables describing race or ethnicity.\nThe brief label from CHR 2023 column in Table B are shown in the first (deleted in R) row in the raw .csv file for 2023, and are also specified in the 2023 CHR Analytic Data Documentation PDF file.\nA key issue for developing these variables is correctly specifying the units of measurement (note that the indexes don’t have units) so that you should be careful to note that in selecting your variables."
  },
  {
    "objectID": "data.html#clean-and-rename-your-selected-variables",
    "href": "data.html#clean-and-rename-your-selected-variables",
    "title": "Project A Data",
    "section": "5.4 Clean and Rename Your Selected Variables",
    "text": "5.4 Clean and Rename Your Selected Variables\nFind each of your five selected variables in Table B, then do what is suggested in the Cleaning Requirements section as part of your data development work for that variable. All of your selected variables should be renamed (and it would help also to apply clean_names() from the janitor package) so as to have descriptive and maximally helpful variable names.\nUse the (cleaned and renamed) version of each variable in your work going forward.\n\nFor example, if you have decided to use as a quantitative variable something like v009_rawvalue, which is about adult smoking, you should rename the variable v009_rawvalue to adult_smoking in your tibble.\nIf you plan to use the variable as your categorical predictor, you should still make the appropriate change to the original quantitative version as indicated in Table B."
  },
  {
    "objectID": "data.html#footnotes",
    "href": "data.html#footnotes",
    "title": "Project A Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn Analysis 3, we will also use CHR 2018 as you’ll see↩︎"
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Examples",
    "section": "",
    "text": "1 Project A Proposal Materials\n\nThe sample proposal using 2019 data is available now. The Quarto file is called 431-projA-sample-portfolio.qmd and it is part of the regular downloads of data and code at our 431-data site. I would start by looking at the HTML result we’ve posted to RPubs.\nThe proposal template, which we used to build the sample proposal, is also available as part of the 431-data site. It is called 431-projA-portfolio-template.qmd. The HTML version is also at RPubs.\n\n\n\n2 Project A Portfolio Report Materials\n\nThe portfolio report template, which we used to build the sample portfolio report, is also available as part of the 431-data site. It is called 431-projA-report-template.qmd. The HTML version is also at RPubs.\nThe sample portfolio report adds only a little to what you had in the sample proposal (since I chose not to work through the Analyses for you), but it is available as part of the 431-data site. It is called 431-projA-sample-report.qmd. The HTML version is also at RPubs.\n\n\n\n3 Sample Analyses using the Favorite Movies Data\n\nFavorite Movies: Analysis 1 (Simple Regression), with Quarto code available at our 431-data site.\nFavorite Movies: Analysis 2 (Independent Samples), with Quarto code available at our 431-data site.\nFavorite Movies: Analysis 3 (Paired Samples), with Quarto code available at our 431-data site."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "431 Project A Instructions",
    "section": "",
    "text": "The Data page contains information on the data you’ll use, and on the required cleaning and development of your final project tibble.\n\nYou’ll need to complete six data management tasks. Start this in early September.\n\nThe Proposal page describes the elements of the proposal, which you will submit in early October, according to the deadline on the Course Calendar.\n\nYou will build your Proposal in September.\n\nThe Analyses page contains information on the analyses you’ll include in your final submission after we accept your Proposal.\nThe Portfolio page describes the elements of the final Project A submission, which includes the final report, the presentation and the self-evaluation. This page also provides submission instructions.\n\nYou will build these items in October.\n\nThe Examples page provides templates for the Proposal and for the Final Portfolio Report, and examples we’ve developed to help you produce what we’re looking for in Project A.\nThe top menu also provides links to contact us, and to the 431 home page.\n\nAll of Project A can be completed using ideas we will discuss in Classes 1-12 in the 431 course."
  },
  {
    "objectID": "index.html#deliverables",
    "href": "index.html#deliverables",
    "title": "431 Project A Instructions",
    "section": "2.1 Deliverables",
    "text": "2.1 Deliverables\nThere are two deadlines, each of which is specified on the Course Calendar.\n\nThe Proposal is due at the start of October. Here you will answer a few specific questions after creating a clean “tibble” for the project, including rows (“counties”) and columns (“variables”) you will choose from options we provide.\n\nYou’ll also need to tell us in the Proposal whether you are working alone or with another person.\n\nThe Portfolio is due at the end of October, and includes:\n\na report in Quarto, rendered as HTML of all of your work,\na presentation which highlights some key findings from your report, and\na self-evaluation form, which you’ll complete after submitting the presentation and report"
  },
  {
    "objectID": "index.html#cleaning-the-data",
    "href": "index.html#cleaning-the-data",
    "title": "431 Project A Instructions",
    "section": "3.1 Cleaning the Data",
    "text": "3.1 Cleaning the Data\nTo build your data set, which will be a sample of the full data, you will do a series of things in R.\n\nYou’ll select a subset of six states (Ohio will automatically be one of them, so you’ll be selecting five others from a list we will provide) which together include at least 300 and no more than 800 counties.\nYou’ll select five different quantitative variables from the County Health Rankings data, from a list of 45 options we provide for you.\n\nOne of these variables will serve as your outcome for Analysis 1.\nAnother will serve as your predictor for Analysis 1.\nA third will serve as your outcome for Analysis 2.\nYour fourth variable will serve (after categorizing1) as your predictor for Analysis 2.\nThe fifth variable will serve as your outcome for Analysis 3, and here we’ll have to pull in some data from the 2018 version of County Health Rankings, as well.\n\nIn addition to the five analytic variables listed above, you will add a factor describing some groups within the fourth variable, as well as four pre-specified variables (the county’s FIPS code, the state postal abbreviation, the county name, and an indicator that the county is ranked by CHR.)\nYou will also add 2018 data for your fifth variable, using a data set we provide.\nYour final analytic tibble will have 300-800 rows (counties) and eleven columns (variables.)"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "431 Project A Instructions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote: Categorizing quantitative information like this turns out to be a terrible idea in practical model-building. We’re doing this here for pedagogical reasons.↩︎\nThough by no means an original idea, this particular phrasing is stolen from Harry Roberts.↩︎"
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Project A Portfolio",
    "section": "",
    "text": "Your Final Submission involves three parts, a portfolio report, a “highlight” video, and a self-evaluation.\n\n\nYou will submit a polished report in both Quarto and HTML, incorporating a total of 17 sections, as described below. You will also submit your main data file (chr_2023_YOURNAME.Rds) which should have 11 variables in it.\n\n\n\nYou will produce a video in mp4 format of no more than 3 minutes in length regardless of whether you are working alone or in a team.\nProducing a video often takes a full day of work after the portfolio report is finished. Do not leave yourself without the opportunity to do good work on this.\nIn this video, you will describe what you believe to be one of the most important findings for your Analysis 1, and for either your Analysis 2 or your Analysis 3.\n\nIf you are working alone on the project, begin your presentation by introducing yourself and describing your sample (which states you used and specifying the research questions you’ll be addressing in your discussion.)\nIf you are working in a pair, each of you will present one of the two analyses, either in two separate videos (which combined are no more than 3 minutes long) or in one video. In either case, introduce yourself at the start of your portion of the video, and specify the states you used (even though you and your partner will be using the same states) and the research question you’ll be addressing.\nDo not discuss all three analyses in the video - just show Analysis 1 and one of the other two.\nSince you have only 3 minutes to present a highlight from each of two analyses, you need to focus. Do not give a “play by play” of everything you did in the report. Focus on one key visualization to amplify your conclusions for each analysis. Keeping the video under 3 minutes while giving us a clear understanding of what you found is the hard part.\nAll videos should include a clear statement of the research questions for any analyses presented, and justify the responses to those questions with results from the analyses.\nThe video must stand on its own, in the sense that it must be completely understandable to someone who has not read your report, but who is generally familiar with County Health Rankings and its measurements. You need to tell us everything we need to know to evaluate your claims, and no more.\nYour video must show your face at the start (so recording in Zoom is preferable) and then must share graphs and results taken from your report. Do not build new graphs or results that don’t appear in your report.\n\n\n\n\nOnce you have submitted the other two elements of your project, you will each (whether working alone or with a partner) submit a brief self-evaluation via this Google Form. The form should take about 10 minutes to complete, and will open for submissions two weeks prior to the deadline.\n\nIf you’re curious, the form asks you to address multiple issues related to the Project in multiple-choice questions. There are also two little essays that we’ll ask for, which should be written independently from your partner (if you have one).\nYou will summarize the key finding of your Project A study in your own well-chosen words (where your response should be in the neighborhood of 75 words, describing one key finding, which might come from any of your three analyses.)\nAlso, you will tell us what the most important piece of advice is that you wished you’d heard when you began Project A (and we’d like at least 25 words here)."
  },
  {
    "objectID": "portfolio.html#the-report",
    "href": "portfolio.html#the-report",
    "title": "Project A Portfolio",
    "section": "",
    "text": "You will submit a polished report in both Quarto and HTML, incorporating a total of 17 sections, as described below. You will also submit your main data file (chr_2023_YOURNAME.Rds) which should have 11 variables in it."
  },
  {
    "objectID": "portfolio.html#the-highlight-video",
    "href": "portfolio.html#the-highlight-video",
    "title": "Project A Portfolio",
    "section": "",
    "text": "You will produce a video in mp4 format of no more than 3 minutes in length regardless of whether you are working alone or in a team.\nProducing a video often takes a full day of work after the portfolio report is finished. Do not leave yourself without the opportunity to do good work on this.\nIn this video, you will describe what you believe to be one of the most important findings for your Analysis 1, and for either your Analysis 2 or your Analysis 3.\n\nIf you are working alone on the project, begin your presentation by introducing yourself and describing your sample (which states you used and specifying the research questions you’ll be addressing in your discussion.)\nIf you are working in a pair, each of you will present one of the two analyses, either in two separate videos (which combined are no more than 3 minutes long) or in one video. In either case, introduce yourself at the start of your portion of the video, and specify the states you used (even though you and your partner will be using the same states) and the research question you’ll be addressing.\nDo not discuss all three analyses in the video - just show Analysis 1 and one of the other two.\nSince you have only 3 minutes to present a highlight from each of two analyses, you need to focus. Do not give a “play by play” of everything you did in the report. Focus on one key visualization to amplify your conclusions for each analysis. Keeping the video under 3 minutes while giving us a clear understanding of what you found is the hard part.\nAll videos should include a clear statement of the research questions for any analyses presented, and justify the responses to those questions with results from the analyses.\nThe video must stand on its own, in the sense that it must be completely understandable to someone who has not read your report, but who is generally familiar with County Health Rankings and its measurements. You need to tell us everything we need to know to evaluate your claims, and no more.\nYour video must show your face at the start (so recording in Zoom is preferable) and then must share graphs and results taken from your report. Do not build new graphs or results that don’t appear in your report."
  },
  {
    "objectID": "portfolio.html#the-self-evaluation",
    "href": "portfolio.html#the-self-evaluation",
    "title": "Project A Portfolio",
    "section": "",
    "text": "Once you have submitted the other two elements of your project, you will each (whether working alone or with a partner) submit a brief self-evaluation via this Google Form. The form should take about 10 minutes to complete, and will open for submissions two weeks prior to the deadline.\n\nIf you’re curious, the form asks you to address multiple issues related to the Project in multiple-choice questions. There are also two little essays that we’ll ask for, which should be written independently from your partner (if you have one).\nYou will summarize the key finding of your Project A study in your own well-chosen words (where your response should be in the neighborhood of 75 words, describing one key finding, which might come from any of your three analyses.)\nAlso, you will tell us what the most important piece of advice is that you wished you’d heard when you began Project A (and we’d like at least 25 words here)."
  },
  {
    "objectID": "portfolio.html#hint-more-isnt-better.",
    "href": "portfolio.html#hint-more-isnt-better.",
    "title": "Project A Portfolio",
    "section": "6.1 Hint: More isn’t better.",
    "text": "6.1 Hint: More isn’t better.\nTo improve your grade, perform the elements of the data science cycle (ingestion, tidying, transforming, visualizing, modeling and communicating) more effectively. Presenting work that isn’t relevant to addressing the issues in question will not help your grade. Also, rehearse your video and make sure you present clearly and understandably throughout the (very short) presentation. Make clear choices about what to include - that’s key. Do not just show us everything you did.\nA stronger grade will be associated with doing the tasks we’ve discussed more effectively. Adding a lot of additional and unnecessary analyses/work without editing down to the important issues will not improve your grade, but rather have the opposite effect. We want to see polished, accurate, clear work. Making things clearer is the hardest thing to do, and so it’s the thing that impresses us most."
  },
  {
    "objectID": "proposal.html",
    "href": "proposal.html",
    "title": "Project A Proposal",
    "section": "",
    "text": "You will develop and send to us (through Canvas):\n\nthe analytic tibble (as an .Rds data file) you developed following the Data page instructions,\na Quarto (.qmd) file containing your data management work, and the other elements required in the proposal, and\nthe HTML result of rendering your Quarto file.\n\nThe deadline for the Project A Proposal is on the Course Calendar\n\n\n\n\n\n\nNote\n\n\n\n\nUse spell check on your Quarto file before rendering it, and review the HTML result carefully to ensure that no residual warnings or error messages remain in the document.\nWhen we run the Quarto file, it needs to produce your HTML file without errors? (Note: warnings or messages are OK at this stage, but it has to work.)\nDo not suppress the R code at any point in the document. All R code should be echoed.\nIf you are working with a partner, exactly one of you should submit the materials to Canvas, and the other partner should submit a text document (Word or PDF is fine) to Canvas that reads: “My name is [YOUR NAME]. I am working on Project A with [INSERT FULL NAME OF YOUR PARTNER], and they will submit the materials for the proposal.”\n\n\n\nTo complete the proposal, you will need to have completed all six Data Tasks on our Data page but none of the work described on our Analyses page"
  },
  {
    "objectID": "proposal.html#section-1.-r-packages",
    "href": "proposal.html#section-1.-r-packages",
    "title": "Project A Proposal",
    "section": "5.1 Section 1. R Packages",
    "text": "5.1 Section 1. R Packages\nAll necessary packages (and no unused packages) should be loaded at the start of the work, and all warnings or messages associated with that loading are suppressed in the HTML result.\n\n\n\n\n\n\nNote\n\n\n\nIt seems impossible to do this work without the Hmisc, janitor, naniar, sessioninfo and tidyverse packages. Remember that the tidyverse should be loaded last. The use of other packages is up to you."
  },
  {
    "objectID": "proposal.html#section-2.-data-ingest",
    "href": "proposal.html#section-2.-data-ingest",
    "title": "Project A Proposal",
    "section": "5.2 Section 2. Data Ingest",
    "text": "5.2 Section 2. Data Ingest\nThis section should display the results of following the instructions in Data Task 1 from the Data page. In this section, you should ingest the raw data into chr_2023_raw and then filter to the ranked counties, producing a tibble with 3082 rows and 720 columns. Do not list the tibble, but use R code to demonstrate that your work meets this requirement.\n\n\n\n\n\n\nNote\n\n\n\nWe will want to check that the project ingests the data properly. This means that you have eliminated the correct row (in any way that works) as you import the data, and that you have used read_csv() to read in the data, thus creating a tibble."
  },
  {
    "objectID": "proposal.html#section-3.-state-selection",
    "href": "proposal.html#section-3.-state-selection",
    "title": "Project A Proposal",
    "section": "5.3 Section 3. State Selection",
    "text": "5.3 Section 3. State Selection\nThis section follows the instructions for Data Task 2. Here, you will identify your six states by postal abbreviation code and name, and write a sentence or two describing your motivation for these selections. You will also demonstrate that your selection yields a new tibble with 300-800 counties, all of which are ranked, and that you have converted the state variable of postal abbreviation codes to a factor.\n\n\n\n\n\n\nNote\n\n\n\n\nWhich states were chosen needs to be clear, and we’ll want to read a sentence about why you chose the states you did.\nThis must lead to 300-800 counties, and this number (total number of counties) must be clear from the document (both the number of rows in the final tibble and in writing.)\nDo not drop any counties from any of the states you selected in the development of your tibble."
  },
  {
    "objectID": "proposal.html#section-4.-variable-selection",
    "href": "proposal.html#section-4.-variable-selection",
    "title": "Project A Proposal",
    "section": "5.4 Section 4. Variable Selection",
    "text": "5.4 Section 4. Variable Selection\nThis section follows the instructions for Data Task 3. Here, you will provide code to identify and select a total of nine variables, including the four required and your five selected variables."
  },
  {
    "objectID": "proposal.html#section-5.-variable-cleaning-and-renaming",
    "href": "proposal.html#section-5.-variable-cleaning-and-renaming",
    "title": "Project A Proposal",
    "section": "5.5 Section 5. Variable Cleaning and Renaming",
    "text": "5.5 Section 5. Variable Cleaning and Renaming\nFor each of your selected variables, you will use the instructions in Data Task 3 to complete appropriate cleaning of the variable, and replace the initial version with your cleaned alternative, renaming each selected variable as you go."
  },
  {
    "objectID": "proposal.html#section-6.-creating-the-analysis-2-predictor",
    "href": "proposal.html#section-6.-creating-the-analysis-2-predictor",
    "title": "Project A Proposal",
    "section": "5.6 Section 6. Creating the Analysis 2 Predictor",
    "text": "5.6 Section 6. Creating the Analysis 2 Predictor\nUse the instructions in Data Task 4 to develop the binary factor that you will use as your Analysis 2 predictor. Be sure to describe the exact cutpoints used in creating the low and high groups, and demonstrate that the resulting factor has approximately 40% of your original observations in the low group, 40% in the high group, and missing data for the middle 20%."
  },
  {
    "objectID": "proposal.html#section-7.-adding-2018-data-for-the-analysis-3-outcome",
    "href": "proposal.html#section-7.-adding-2018-data-for-the-analysis-3-outcome",
    "title": "Project A Proposal",
    "section": "5.7 Section 7. Adding 2018 Data for the Analysis 3 Outcome",
    "text": "5.7 Section 7. Adding 2018 Data for the Analysis 3 Outcome\nUse the instructions in Data Task 5 to include the 2018 version of your Analysis 3 outcome as a variable in your tibble. This should give you a total of 11 variables."
  },
  {
    "objectID": "proposal.html#section-8.-arranging-and-saving-the-analytic-tibble",
    "href": "proposal.html#section-8.-arranging-and-saving-the-analytic-tibble",
    "title": "Project A Proposal",
    "section": "5.8 Section 8. Arranging and Saving The Analytic Tibble",
    "text": "5.8 Section 8. Arranging and Saving The Analytic Tibble\nAfter renaming your variables, arrange the 11 variables in your chr_2023 tibble into the order specified in Data Task 6.\nThen save the tibble as an R data set. Don’t make any changes to the tibble after this point."
  },
  {
    "objectID": "proposal.html#section-9.-print-the-tibble",
    "href": "proposal.html#section-9.-print-the-tibble",
    "title": "Project A Proposal",
    "section": "5.9 Section 9. Print the Tibble",
    "text": "5.9 Section 9. Print the Tibble\nYou will show that your chr_2023 tibble is in fact a tibble and not just a data frame by listing it, so that we can see that the first 10 rows are printed, and the columns are appropriately labeled. The command you want is just chr_2023."
  },
  {
    "objectID": "proposal.html#section-10.-numerical-summaries",
    "href": "proposal.html#section-10.-numerical-summaries",
    "title": "Project A Proposal",
    "section": "5.10 Section 10. Numerical Summaries",
    "text": "5.10 Section 10. Numerical Summaries\nYou will display the results of describe() from the Hmisc package, run on the entire tibble.\n\nWe need to see minimum and maximum values that make sense, and also that each of your variables shows the appropriate number of counties."
  },
  {
    "objectID": "proposal.html#section-11.-the-codebook",
    "href": "proposal.html#section-11.-the-codebook",
    "title": "Project A Proposal",
    "section": "5.11 Section 11. The Codebook",
    "text": "5.11 Section 11. The Codebook\nBegin this section with a statement of the number of counties and variables (should be eleven) in your tibble.\nA codebook, including your revised and the original variable names, counts of distinct and missing values, definitions and a clear indication of the cutpoints for your binary factor is the next step.\nAfter you select your variables, use the County Health Rankings website’s 2023 Measures list, and in particular the linked information on that page for full descriptions, definitions and limitations of the variables you have selected.\nFor more details of what we’re looking for here, please refer to the sample codebook provided as part of the sample proposal and the proposal template in the Examples section.\n\n\n\n\n\n\nNote\n\n\n\n\nYou have an attractively formatted, readable codebook that looks nice in your HTML. The example proposal provides an example, but you can come up with something better if you like. It must be run within Quarto though - you cannot submit an image instead of getting the codebook through code.\nYour selected five variables are clear, and there is information about what the variables mean and why you chose them, and the role they will play in your eventual analyses, specifically you clearly specify which will serve as the Analysis 1 outcome, the Analysis 1 predictor, the Analysis 2 outcome, the quantitative version of your Analysis 2 predictor, and the Extra Variable.\nFor each of your quantitative variables you specify their units in appropriate language drawn from the measure specifications at County Health Rankings (after incorporating appropriate cleaning as described in Data Task 3.\nYou specify all variables using the name you will use in your final tibble, the vXXX code from the original data, and show that you have some understanding of what the variable means, how it was collected and why it is important in the sentences you write below, after your codebook.\n\n\n\nAt the end of this section, you should complete checks that:\n\nYou have at least 15 distinct values across your sample of counties for your Analysis 1 variables, your Analysis 2 outcome and your Analysis 3 outcome (in each year.)\nYou have no more than 20% missing values in your Analysis 1 variables, your Analysis 2 outcome and your Analysis 3 outcome (in each year.)\nYou have no missing data at all in your identifying variables (fipscode, state, county) nor in your county_ranked variable, and that you have a distinct fipscode for every row in your tibble."
  },
  {
    "objectID": "proposal.html#section-12.-your-research-questions",
    "href": "proposal.html#section-12.-your-research-questions",
    "title": "Project A Proposal",
    "section": "5.12 Section 12. Your Research Questions",
    "text": "5.12 Section 12. Your Research Questions\nIn this section, you will provide three research questions, one each for Analysis 1, Analysis 2, and Analysis 3. It would help to provide subsections within this section, as I have done in the Sample Proposal and Proposal Template.\nFor each analysis …\n\nStart by describing what you want to study, and then specify a research question (which should end with a question mark and be something you can resolve with the planned analysis.)\nDon’t boil the ocean here. You’re looking for a research question that can be reasonably addressed using your data, so it has to be pretty straightforward.\nIf you have a pre-existing belief about what will happen, before you look at the data, please feel encouraged to include a statement about that belief before specifying your question.\n\n\n5.12.1 Your Research Question for Analysis 1\nHere you will propose your Research Question for Analysis 1 and provide some motivation for your variable choices associated with that analysis. A trio of well-developed research questions in this section is the most important part of this portfolio.\n\nA research question will end with a question mark, and will be something you will be able to answer (or at least respond to effectively) after your Analysis 1 is complete.\nUse one research question for Analysis 1, another for Analysis 2, and a third for Analysis 3.\n\nAfter listing your question, you should provide some brief speculation as to the nature of the relationship you anticipate finding based on your hypotheses about the variables you plan to study (following my tips below.)\n\n5.12.1.1 Tips for the research question in Analysis 1\n\nExamples of dull but moderately effective and minimally appropriate research questions for Analysis 1 would be:\n\nHow well does a linear model using [predictor] predict [outcome], in [number] counties in the states of [list of your states]?\nor\nWhat is the nature of the association between [predictor] and [outcome], in [number] counties in the states of [list of your states]?\n\nYou should be able to do meaningfully better than that, especially if you have a reason to believe something in advance about the direction or strength of the association you are anticipating.\nHowever, if you’re struggling, using that format will be OK.\nA research question uses formal but clear language.\nGiven your planned analyses, stay away from statements about cause and effect, and don’t use the words correlate or regression (in any form) in your research question.\n\n\n\n\n5.12.2 Research Question for Analysis 2\nHere you will propose your Research Question for Analysis 2 and provide some motivation for your variable choices associated with that analysis. All of the tips for Analysis 1 apply in this case, too.\n\nPlease remember that a research question for this course should end in a question mark.\nAgain, after listing your question, it is completely appropriate for you to provide some brief speculation as to the nature of the relationship you anticipate finding based on your hypotheses about the variables you plan to study.\nAn example of a dull but moderately effective and minimally appropriate research question for Analysis 2 might be:\n\nAre there meaningful differences in the mean of [outcome] for counties with high and low levels of [predictor]?\nAgain, you should be able to do a bit better than that.\n\n\n5.12.3 Research Question for Analysis 3\nHere you will propose your Research Question for Analysis 3, and provide some motivation for your variable choices associated with that analysis. All of the tips for Analysis 1 apply in this case, too.\n\nPlease remember that a research question for this course should end in a question mark.\nAgain, after listing your question, it is completely appropriate for you to provide some brief speculation as to the nature of the relationship you anticipate finding based on your hypotheses about the variables you plan to study.\nAn example of a dull but moderately effective and minimally appropriate research question for Analysis 3 might be:\n\nAre there meaningful differences in the mean of [outcome] for counties in 2023 as compared to 2018?\nAgain, you should be able to do a bit better than that."
  },
  {
    "objectID": "proposal.html#section-13.-reflection",
    "href": "proposal.html#section-13.-reflection",
    "title": "Project A Proposal",
    "section": "5.13 Section 13. Reflection",
    "text": "5.13 Section 13. Reflection\nHere you will provide a paragraph describing the most challenging (or difficult) part of completing the work so far, and how you were able to overcome whatever it was that was most challenging.\nYour discussion of the biggest challenge includes a paragraph (or more) written in English, with attention paid to grammar, syntax and spelling. It needs to be clear to us from reading your reflection what your biggest issue was, and how you tried to address it."
  },
  {
    "objectID": "proposal.html#section-14.-session-information",
    "href": "proposal.html#section-14.-session-information",
    "title": "Project A Proposal",
    "section": "5.14 Section 14. Session Information",
    "text": "5.14 Section 14. Session Information\nAs we have required in our Labs, there must be a Session Information section at the end of the document. This should indicate that R version 4.3.1. or later is used.\nWe’d like you to use the xfun package’s version of session_info()."
  }
]